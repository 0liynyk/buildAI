# README.md

## üß† AI Server (MVP)

–¶–µ–π –ø—Ä–æ–µ–∫—Ç ‚Äî –º—ñ–Ω—ñ–º–∞–ª—å–Ω–∏–π AI-—Å–µ—Ä–≤–µ—Ä –Ω–∞ –±–∞–∑—ñ FastAPI, Ollama, FAISS (RAG) —ñ Whisper.

### üì¶ –ö–æ–º–ø–æ–Ω–µ–Ω—Ç–∏:
- **FastAPI** ‚Äî HTTP API
- **Ollama** ‚Äî LLM (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, LLaMA3)
- **FAISS** ‚Äî –ø–æ—à—É–∫ –ø–æ –≤–µ–∫—Ç–æ—Ä–Ω–æ–º—É —ñ–Ω–¥–µ–∫—Å—É
- **Whisper** ‚Äî —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü—ñ—è –∞—É–¥—ñ–æ –≤ —Ç–µ–∫—Å—Ç

---

### üöÄ –†–æ–∑–≥–æ—Ä—Ç–∞–Ω–Ω—è

#### 1. –ö–ª–æ–Ω—É–≤–∞–Ω–Ω—è —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä—ñ—é
```bash
git clone https://github.com/yourusername/ai-server.git
cd ai-server
```

#### 2. –ó–∞–ø—É—Å–∫ –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é docker-compose
```bash
docker-compose up --build
```

#### 3. –ê–±–æ –æ–∫—Ä–µ–º–æ (–ª–∏—à–µ FastAPI)
```bash
docker build -t ai-server-api .
docker run -p 8000:8000 --env-file .env ai-server-api
```

---

### üîó API endpoints

- `GET /` ‚Äî –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å—É
- `POST /llm` ‚Äî –∑–∞–ø–∏—Ç –¥–æ LLM
  ```json
  { "prompt": "–ü—Ä–∏–≤—ñ—Ç, —è–∫ —Å–ø—Ä–∞–≤–∏?" }
  ```
- `POST /rag` ‚Äî –∑–∞–ø–∏—Ç –¥–æ —Å–∏—Å—Ç–µ–º–∏ RAG
  ```json
  { "question": "–©–æ —Ç–∞–∫–µ FAISS?" }
  ```
- `POST /whisper` ‚Äî –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è `.wav` —Ñ–∞–π–ª—É –¥–ª—è —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –º–æ–≤–ª–µ–Ω–Ω—è

---

### ‚öôÔ∏è –í–∏–º–æ–≥–∏
- Docker + docker-compose
- Ollama —Ç–∞ Whisper –ø–æ–≤–∏–Ω–Ω—ñ –±—É—Ç–∏ –∑–∞–ø—É—â–µ–Ω—ñ —è–∫ —Å–µ—Ä–≤—ñ—Å–∏ (–Ω–∞–ª–∞—à—Ç–æ–≤—É—é—Ç—å—Å—è –≤ docker-compose.yml)
- –ó–º—ñ–Ω–Ω—ñ —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞ —É `.env`

---

### ‚öôÔ∏è –ó–º—ñ–Ω–Ω—ñ —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞
`.env` —Ñ–∞–π–ª:
```
OLLAMA_HOST=http://ollama:11434
RAG_ENDPOINT=http://faiss:8001/query
WHISPER_COMMAND=whisper --model base --language en
```

---

### üîÅ CI/CD (GitHub Actions)
–§–∞–π–ª `.github/workflows/deploy.yml` –∑–∞–ø—É—Å–∫–∞—î CI:
```yaml
name: CI/CD

on:
  push:
    branches:
      - main

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      - name: Install dependencies
        run: pip install -r requirements.txt
      - name: Lint and Test
        run: |
          echo "Add your linting and testing here"
```

> –°—Ç–≤–æ—Ä–∏ —Ñ–∞–π–ª `.github/workflows/deploy.yml` —Ç–∞ –≤—Å—Ç–∞–≤ —Ü–µ–π –∫–æ–¥.

---

### üì¶ docker-compose.yml
```yaml
version: '3.9'

services:
  api:
    build: .
    ports:
      - "8000:8000"
    env_file:
      - .env
    depends_on:
      - ollama
      - faiss
      - whisper

  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama

  faiss:
    image: your-faiss-service:latest
    ports:
      - "8001:8001"

  whisper:
    image: your-whisper-service:latest
    command: ["--model", "base", "--language", "en"]

volumes:
  ollama_data:
```

> –°—Ç–≤–æ—Ä–∏ —Ñ–∞–π–ª `docker-compose.yml` —Ç–∞ –≤—Å—Ç–∞–≤ —Ü–µ–π –≤–º—ñ—Å—Ç.

---

üë§ –ê–≤—Ç–æ—Ä: [Roman]

---

### ‚úÖ –ü–ª–∞–Ω–∏
- –î–æ–¥–∞—Ç–∏ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü—ñ—é
- –ü—ñ–¥–∫–ª—é—á–∏—Ç–∏ Qdrant –∑–∞–º—ñ—Å—Ç—å FAISS
- CI/CD (GitHub Actions)
- K8s Helm —á–∞—Ä—Ç–∏ –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–Ω-–æ—Ä—ñ—î–Ω—Ç–æ–≤–∞–Ω–æ–≥–æ —Ä–æ–∑–≥–æ—Ä—Ç–∞–Ω–Ω—è
- –Ü–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—è –∑ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∏–º–∏ —Å–µ—Ä–≤—ñ—Å–∞–º–∏ —á–µ—Ä–µ–∑ API Gateway
